<!doctype html>
<html lang="en">

<head>
  <!--<h2>hello</h2> -->
  <title>Team Tiburon &mdash; The AUV Team Of NITR</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="shortcut icon" href="https://github.com/auvnitrkl/webAssets/blob/main/images/favicon.ico?raw=true">
  <link rel="stylesheet" href="css/custom-bs.css">
  <link rel="stylesheet" href="css/jquery.fancybox.min.css">
  <link rel="stylesheet" href="fonts/icomoon/style.css">
  <link rel="stylesheet" href="fonts/line-icons/style.css">

  <!-- MAIN CSS -->
  <link rel="stylesheet" href="css/style.css">
  <!-- FONTAWESOME -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.2.0/css/all.min.css">
  
</head>

<body>
  <!-- it is used to show the spining circle before loading the page-->
  <div class="loader">
    <div class="spinner-border text-primary" role="status">
      <span class="sr-only">Loading...</span>
    </div>
  </div>
  <!-- use for menu in narrow screen mode-->
  <div class="site-wrap">
    <div class="site-mobile-menu site-navbar-target">
      <div class="site-mobile-menu-header">
        <img style="margin-left: 10px;  padding: 5px;" class="img-fluid" height="45" width="45" src="https://github.com/auvnitrkl/webAssets/blob/main/images/logo.png?raw=true"></a>
        <div class="site-mobile-menu-close mt-3">
          <span class="icon-close2 js-menu-toggle"></span>
        </div>
      </div>
      <div class="site-mobile-menu-body"></div>
    </div> <!-- .site-mobile-menu -->
    <!-- NAVBAR -->
    <header class="site-navbar" id="top">
      <div class="container-fluid">
        <div class="dark-div">
          <button onclick="darkTheme()">DM</button>
        </div>
        <div class="row align-items-center">
          <div class="site-logo col-8"><a href="index.html">
              TIBURON</a>
            <a href="index.html"><img style="margin-left: 10px;  padding: 5px;" class="img-fluid" height="45" width="45" src="https://github.com/auvnitrkl/webAssets/blob/main/images/logo.png?raw=true"></a>
            <iframe src="https://www.facebook.com/plugins/like.php?href=https%3A%2F%2Fwww.facebook.com%2Ftiburonauv%2F&amp;width=72&amp;layout=button_count&amp;action=like&amp;size=small&amp;show_faces=true&amp;share=true&amp;height=21&amp;appId"
              width="140" height="20" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
          </div>
          <nav class="mx-auto site-navigation">
            <ul class="site-menu js-clone-nav d-none d-lg-block">
              <li><a href="index.html">Home</a></li>
              <li><a href="team.html">The Team</a></li>
              <li><a href="achievements.html">Achievements</a></li>
              <li><a href="gallery.html">Gallery</a></li>
              <li><a href="events.html">Technical Events</a></li>
               <li><a href="robosub21.html">Robosub 2021</a></li>
              <li><a href="sponsors.html">Sponsors</a></li>
              <li><a href="contact.html">Contact Us</a></li>
            </ul>
          </nav>
          <div class="col-4 site-burger-menu d-block d-lg-none text-right">
            <a href="#" class="site-menu-toggle js-menu-toggle"><span class="icon-menu h3"></span></a>
          </div>
        </div>
      </div>
    </header>
    <section class="site-navbar2" id="top2">
      <div>
        <img class="img-fluid" height="75" width="75" src="https://github.com/auvnitrkl/webAssets/blob/main/images/logo.png?raw=true">
      </div>
    </section>
    <!-- HOME -->
    <section class="home-section section-hero overlay slanted" id="home-section">
      <div class="container">
        <div class="row align-items-center justify-content-center">
          <div class="col-md-8 text-center">
            <h1><strong>Team Tiburon</strong></h1>
            <h2 style="color:cornsilk;">The AUV Team Of NIT Rourkela</h2>
            <div class="mx-auto w-75">
              <!--need to change this line -->
              <h3 style=" color:rgb(191, 191, 191)">Group of committed engineers working to design the best tech to understand the marine ways.</h3>
            </div>
            <p class="mt-5"><a href="#inductions" class="btn btn-outline-white btn-md ">INDUCTION PROCESS</a></p>
          </div>
        </div>
      </div>
      <!-- VIDEO -->
      <div class="video-container">
        <video autoplay loop="true" controls muted>
          <source type="video/mp4" src="https://github.com/auvnitrkl/webAssets/blob/main/videos/tiburon.mp4?raw=true">
        </video>
      </div>
      <a href="#about-us-section" class="scroll-button smoothscroll">
        <span class=" icon-keyboard_arrow_down"></span>
      </a>
    </section>
    <!-- ABOUT US -->

    <section class="site-section about-us-section container">
        <div class="row m-3 bg-success">
            <div class="col-lg-6 col-sm-12 d-flex justify-content-center">
                <h1>ROBOSUB 2021</h1>
            </div>
            <div class="col-lg-6 col-sm-12 d-flex justify-content-center">
                <button class="btn-dark m-1 w-25"><a class="text-light" href="./tdr/SoftwareTDR.pdf">Software TDR</a></button>
                <button class="btn-dark m-1 w-25"><a class="text-light" href="./tdr/TiburonTDR.pdf">Electronics TDR</a></button>
                <button class="btn-dark m-1 w-25"><a class="text-light" href="./tdr/MechTDR.pdf">Mechanical TDR</a></button>
            </div>
        </div>

        <h2>Software Subsystem</h2>
        <div>
            <h3>Visual Object Detection:</h3> 
            <b>Computer Vision(CV)</b> <br>
            <ol>
                <li><b>OpenCV:</b> We as a team have been using OpenCV to perform image processing techniques to extract information from camera frames and detect obstacles & tasks at hand in many of our previous competitions. We used bounding box vertices to locate tasks such as gates & bins. These detections also helped in localizing our bot as by applying basic math similarity concept we were able to estimate the position of our bot with respect to task (having the focal length of the camera at hand and the original length and width of task objects and it comparing with the ratio of pixel lengths of edges). The center we calculated from the contours/hough lines made around the task(gates) helped in aligning the bot and pass through the gate.
                    Neural Network</li>
                <li><b>YOLOv3/v5:</b> Although traditional image processing methods were successful in detecting objects underwater(with suitable adjustment in HSV values as per lighting) but it comes with certain drawbacks such as failing to detect from a greater distance and unreliable results in different lighting and background. Here we have found Yolov3(You Only Look Once) CNN ( a real-time object detection algorithm that identifies specific objects in videos, live feeds, or images.)to be effective. We realized if we can navigate to the object close enough using this neural network-based model, then we can apply suitable thresholding techniques or can use the same model to get the center and pass through the target(gate) or reach the task at hand. For training the CNN, images were collected from previous competitions. Data augmentation was also performed to introduce variation and increase the dataset. We used our own Labeler Toolbox to label the images. 1/5th of the images were reserved as the test set to run the inference and the model(based on open-source neural network framework Darknet) was trained on the rest of the data. Unfortunately, we could not test the model real-time underwater on Nvidia Jetson due to the pandemic, but we still achieved very encouraging results testing it on our local systems(25 fps 87%).
                    Together with new machine learning approaches, traditional image processing techniques, color correction algorithms, and other fine-tuned approaches, we hope to strengthen the perception system of Makara 4.0
                </li>
            </ol>
            <h3>Better Perception Techniques:</h3>
            <ol>
                <li><b>Glare Removal</b>Sometimes the images obtained from the bottom camera are too bright and keep fluctuating due to sunlight reflection(happens when the arena isn't that deep and has a shiny bottom surface). To remove glares from these images we have used an algorithm to make them more visible and clear.
                    The algorithm keeps track of the most recent 'n' images and finds the median, mean variation of 'n' RGB values respectively for each pixel in the image. The final image obtained has less glare and the lighting is spread equally. As the glares are rapidly moving due to surface water motion, taking its median helps to distribute its intensity and makes the image more clear and visible.
                </li>

                <li><b>Color Correction</b>The Robosub arena watercolor is greenish and unclear and thus making things difficult for the object detection model as they are trained on a different environment.
                    To change the color and make it more natural blue, we have simply changed the weight of the RGB channel of the image (called Stretching) and obviously, the weight of the green channel needs to be reduced. Then to remove the fogginess in the image we used the Contrast Limited Adaptive Histogram Equalization (CLAHE) algorithm that helped to increase the image contrast and made images more clear.
                </li>
            </ol>

            

            <h3>Model Optimisation:</h3>
            <p>The perception stack is mostly carried out by object detection methods using deep neural networks. However, there has always been a trade-off between accuracy and real-time fps. We have approached this problem with model optimization using quantization by implementing state-of-the-art quantization-aware training methods. This approach simply converts all float32 weights and activations to int8 thus drastically reducing model size as well as the inference time. This enables us to use any low-power computing devices and stack multiple models in our pipeline without compromising performance.
            </p>

            <h3>Stereo Vision:</h3>
            <p>In traditional stereo vision, two cameras, displaced horizontally from one another are used to obtain two differing views on a scene, in a manner similar to human binocular vision. By comparing these two images, the relative depth information can be obtained in the form of a disparity map, which encodes the difference in horizontal coordinates of corresponding image points. Computer vision algorithms are also applied to images for smoothening and rectification of the images. Thus by using stereo vision we can perceive the distance between the object and the camera plane while carrying out various tasks during the mission.</p>

            <h3>PID Auto-tuning:</h3>
            <p>The PID controllers used in our AUV have to tune it (that means to obtain the value of Kp, Ki, Kd constants ) manually so that it manoeuvres properly.
                But this time we tried to automate things and decided to build a tuning algorithm using Ant Colony Optimization (ACO). To tune the constants of each degree of freedom, the algorithm first generates some random values and tries to minimize the error generated from a cost function for each generated value and then determine the best values obtained from this generation and use them as the parents for the next generation. This happens generation over generation till we get an optimal value and every generation is more optimal than its previous one.</p>

            <h3>Working with DVL and why ?</h3>
            <p>
                A Doppler Velocity Log (DVL) is an acoustic sensor that estimates velocity relative to the sea bottom. This is achieved by sending a long pulse along with a minimum of three acoustic beams, each pointing in a different direction. Typically, this produces estimates of velocity converted into an XYZ coordinate frame of reference – the DVL’s frame of reference. Together with a heading estimate, these velocity estimates may be integrated over the ping interval to estimate a step-by-step change of position – i.e. displacement = velocity × time step.
                <br>
                It is important to ensure that velocity estimates do not have any bias or offsets because this will lead to a growing error in the position estimate. This is where the Doppler Velocity Log becomes a key in the subsea navigation for its accurate estimate of velocity with zero-mean bias. This sensor combined with the IMU ensures a proper estimation of obstacles/key places that the vehicle needs to avoid/reach to perform some specific work.
                <br>
            </p>
        </div>


    </section>
 

  <footer class="site-footer slanted-footer">

    <a href="index.html#home-section" class="smoothscroll scroll-top">
      <span class="icon-keyboard_arrow_up"></span>
    </a>
    <div class="container">
      <div class="row mb-5">
        <div class="col-6 col-md-3 mb-4 mb-md-0">
          <h3>Technical Events</h3>
          <ul class="list-unstyled">
            <li><a href="https://sauvc.org/">Singapore AUV Challenge(SAUVC)</a></li>
            <li><a href="https://www.niot.res.in/SAVe/">Student Autonomous Underwater Vehicle(SAVe) Competition</a></li>
            <li><a href="https://robosub.org/">RoboSub 2019</a></li>
          </ul>
        </div>
        <div class="col-6 col-md-3 mb-4 mb-md-0">
          <h3>Address</h3>
          <ul class="list-unstyled">
            <li>Technology Innovation and Industry Relations Building, NIT Rourkela</li>
            <li><a href="mailto:tiburonnitr.contact@gmail.com">tiburonnitr.contact@gmail.com</a></li>
          </ul>
        </div>
        <div class="col-6 col-md-3 mb-4 mb-md-0">
          <h3>Faculty Advisor</h3>
          <ul class="list-unstyled">
            <li>Dr Haraprasad Roy</li>
            <li><a href="mailto:royh@nitrkl.ac.in">royh@nitrkl.ac.in</a></li>
          </ul>
        </div>
        <div class="col-6 col-md-3 mb-4 mb-md-0">
          <h3>Contact Us</h3>
          <div class="footer-social">
            <a href="https://www.facebook.com/tiburonauv/"><span class="icon-facebook"></span></a>
            <a href="https://www.twitter.com/auvnitrkl"><span class="icon-twitter"></span></a>
            <a href="https://www.instagram.com/auvnitrkl"><span class="icon-instagram"></span></a>
            <a href="https://www.linkedin.com/school/tiburonauv"><span class="icon-linkedin"></span></a>
            <!--<a href="#"><span class="icon-linkedin"></span></a>-->
          </div>
        </div>
      </div>

      <div class="row text-center">
        <div class="col-12">
          <p class="copyright"><small class="block">
              <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
              Copyright &copy;<script>
                document.write(new Date().getFullYear());
              </script> All rights reserved | Developed from
              <a href="https://colorlib.com" target="_blank">Colorlib</a></a>
              <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
            </small></p>
        </div>
      </div>
    </div>
  </footer>

  </div>

  <!-- SCRIPTS -->
  <script src="js/jquery.min.js"></script>
  <script src="js/bootstrap.bundle.min.js"></script>
  <script src="js/isotope.pkgd.min.js"></script>
  <script src="js/stickyfill.min.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.easing.1.3.js"></script>
  <script src="js/readmore.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.animateNumber.min.js"></script>
  <script src="js/slide-show.js"></script>
  <script src="js/custom.js"></script>
  <script src="js/dark.js"></script>
</body>

</html>
